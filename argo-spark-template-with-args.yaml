apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: spark-py-job-argo-withargs
spec:
  entrypoint: submit-spark-job
  arguments:
    parameters:
    - name: customer-id
    - name: input-json
  templates:
  - name: submit-spark-job
    inputs:
      parameters:
      - name: customer-id
      - name: input-json
    container:
      image: bitnami/kubectl:latest
      command: ["sh", "-c"]
      args:
      - |
        echo "Submitting SparkApplication..."
        cat <<EOF | kubectl apply -f -
        apiVersion: sparkoperator.k8s.io/v1beta2
        kind: SparkApplication
        metadata:
          name: spark-py-job-argo-withargs
          namespace: default
        spec:
          type: Python
          pythonVersion: "3"
          mode: cluster
          mainApplicationFile: local:///opt/spark/json-pi.py
          image: abhilash2018/spark-py-app
          imagePullPolicy: IfNotPresent
          sparkVersion: 3.5.5
          driver:
            cores: 1
            memory: 512m
            serviceAccount: spark-operator-spark
          executor:
            instances: 1
            cores: 1
            memory: 512m
          arguments:
            - "--customer-id"
            - "{{inputs.parameters.customer-id}}"
            - "--input-json"
            - "{{inputs.parameters.input-json}}"
        EOF
